setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
options(stringsAsFactors = F)
setwd("../")



## Load and clean PERSUADE corpus

dat = read.csv("raw data/persuade_2.0_human_scores_demo_id_github.csv")
dat$docID = 1:nrow(dat)
dat = dat %>% select(docID, everything(), -source_text) %>% 
  rename(id=essay_id_comp, 
         text=full_text,
         score=holistic_essay_score,
         prompt=prompt_name, 
         grade=grade_level)




txt=stringi::stri_trim_right(dat$text)
txt2=textclean::replace_non_ascii(txt)
dat$text = iconv(txt2, from="UTF-8",to="ASCII",sub="")

text = tm::stripWhitespace(dat$text)


all.feats = dat %>% select(docID, id, score, grade, task, prompt)

# 2. Make large set of features for the text corpus ----

# Create preliminary text features
feats = rcttext::generate_features( text,
                                    meta = all.feats,
                                    sent = TRUE,
                                    clean_features = FALSE,
                                    read = c("Flesch","Flesch.Kincaid", "ARI"),
                                    ld=c("TTR","R","K"),
                                    ignore=c("docID","id"),
                                    verbose = TRUE )
all.feats = feats

# Load LIWC-generated features
# (This loads file generated by LIWC program and cleans it)
all.feats = rcttext::extract_liwc( file = "external data/persuade-liwc.csv",
                                   meta = all.feats,
                                   ID.liwc = c("docID"),
                                   ID.meta = c("docID"),
                                   clean=FALSE )
dim(all.feats)


if (FALSE){ #Use the code below to generate text embeddings using OpenAI embed-3-small model
	# Replace the text below with your unique API token
	API_KEY = "ENTER API TOKEN"
	Sys.setenv(OPENAI_API_KEY=API_KEY)

	library(openai)

	txt=stringi::stri_trim_right(dat$text)
	txt2=textclean::replace_non_ascii(txt)
	dat$text = iconv(txt2, from="UTF-8",to="ASCII",sub="")
	text = tm::stripWhitespace(dat$text)

	source("scripts/utils.R")
	

	# Generate embeddings and save the results
	embed.small<- get_embeddings(model = "text-embedding-3-small",text= text)
	save(embed.small,file="external data/persuade-embed-3-small.RData")

}


# Add PCA reduction of OpenAI embeddings
load("external data/persuade-embed-3-small.RData")
pca = prcomp(embed.small)
X.pc = as.data.frame(pca$x[,1:50])
names(X.pc)=paste("t3s.PC",1:ncol(X.pc),sep="")


all.feats = cbind(all.feats, X.pc)

# Add output from TAACO
tc = read.csv("external data/persuade-taaco2.1.3.csv")
tc = select(tc, -Filename)

all.feats = merge(all.feats,tc,by="docID")


dim(all.feats)
table( apply(all.feats, 2, anyNA) )

all.info = all.feats

names(all.info) = gsub( "lex_f.ent[, -c(1)]","lex_f.ent", names(all.info), fixed=T )
names(all.info) = gsub( " ", "_", names(all.info), fixed=T )
names(all.info)=gsub("brink-passage","brink.passage",names(all.info))

X = all.info %>% select(-any_of(c("id","docID","score","grade","task","prompt")))
findLinearCombos(X)
nz = caret::nearZeroVar(X, uniqueCut=0.5,freqCut=500/1,names=T)
all.info = all.info[ ,!names(all.info)%in%nz]
X = all.info %>% select(-any_of(c("id","docID","score","grade","task","prompt")))

fc = findCorrelation(cor(X),cutoff=0.91, names=T)
all.info = all.info[ ,!names(all.info)%in%fc]


dat.ML = all.info %>% rename(Yobs=score) %>% select(-docID, -grade, -task, -prompt)


save( dat.ML, 
      file="generated data/prepped_ML_persuade.RData" )

