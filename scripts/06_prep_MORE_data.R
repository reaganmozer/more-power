setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
options(stringsAsFactors = F)
setwd("../")


main=read.csv("raw data/MORE_study_main.csv")

main$docID = 1:nrow(main)
main = select(main, docID, everything())


txt=stringi::stri_trim_right(main$text.sc)
txt2=textclean::replace_non_ascii(txt)
main$text.sc = iconv(txt2, from="UTF-8",to="ASCII",sub="")


all.feats = main %>% select(docID, s_id, grade, subject, more, score)


# 2. Make large set of features for the text corpus ----

# Create preliminary text features
feats = rcttext::generate_features( main$text,
                                    meta = all.feats,
                                    sent = TRUE,
                                    clean_features = FALSE,
                                    read = c("Flesch","Flesch.Kincaid", "ARI"),
                                    ld=c("TTR","R","K"),
                                    ignore=c("docID","s_id"),
                                    verbose = TRUE )

# Load LIWC-generated features
# (This loads file generated by LIWC program and cleans it)
liwc=read.csv("external data/write-main-liwc.csv")
all.feats = merge(feats,liwc,by=c("docID"))

# Add PCA reduction of OpenAI embeddings

if (FALSE){ #Use the code below to generate text embeddings using OpenAI embed-3-small model
  
  # Replace the text below with your unique API token
  API_KEY = "ENTER API TOKEN"
  Sys.setenv(OPENAI_API_KEY=API_KEY)
  
  library(openai)
  
  embeddings = openai::create_embedding(model="text-embedding-3-small", input=main$text)
  emb.main = do.call(rbind, embeddings$data$embedding)
  save(embedding.main, file="external data/write-main-embed-3-small.RData")  
  
}

load("external data/write-main-embed-3-small.RData")
pca = prcomp(embedding.main)
X.pc = as.data.frame(pca$x[,1:50])
names(X.pc)=paste("t3s.PC",1:ncol(X.pc),sep="")


all.feats = cbind(all.feats, X.pc)

# Add output from TAACO
tc = read.csv("external data/write-main-taaco2.1.3.csv")
tc$s_id=as.numeric(gsub("s","",sapply(1:nrow(tc),function(x) strsplit(tc$Filename[x],"_")[[1]][1])))
tc$grade=as.numeric(gsub("grade","",sapply(1:nrow(tc),function(x) strsplit(tc$Filename[x],"_")[[1]][2])))
tc$subject=gsub(".txt","",sapply(1:nrow(tc),function(x) strsplit(tc$Filename[x],"_")[[1]][3]))
tc = select(tc, s_id, grade, subject, everything(), -Filename)

all.feats = merge(all.feats,tc,by=c("s_id","grade","subject"))


dim(all.feats)
table( apply(all.feats, 2, anyNA) )

all.info = all.feats

names(all.info) = gsub( "lex_f.ent[, -c(1)]","lex_f.ent", names(all.info), fixed=T )
names(all.info) = gsub( " ", "_", names(all.info), fixed=T )

X = all.info %>% select(-any_of(c("s_id","docID","score","more","grade","subject")))
lc=caret::findLinearCombos(X)

X = X[,-c(lc$remove)]
nz = caret::nearZeroVar(X, uniqueCut=0.5,freqCut=500/1,names=F)
X = X[,-c(nz)]

all.info = select(all.info, docID, s_id, score, more, grade, subject, names(X))


save( all.info, 
      file="generated data/MORE-main.RData" )

